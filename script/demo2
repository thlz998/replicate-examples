#!/usr/bin/env python3
import sys
from huggingface_hub import login
import torch
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, StableDiffusionPipeline, EulerDiscreteScheduler
# from lora_diffusion import LoRAManager
from PIL import Image

CACHE_DIR = "weights-cache"
sys.path.append(".")
qrImage = Image.open('k0a1a.png')

seed = 1383557390

model_key_base_safetensors = "./weights-cache/models/revAnimated_v122.safetensors"

pipe = StableDiffusionPipeline.from_single_file(
        model_key_base_safetensors,
        torch_dtype=torch.float16,
        cache_dir=CACHE_DIR).to("cuda")

components = pipe.components


controlnet_qr = ControlNetModel.from_pretrained(
        "Nacholmo/controlnet-qr-pattern", 
        torch_dtype=torch.float16,
        cache_dir=CACHE_DIR).to("cuda")

components["controlnet"] = [controlnet_qr, controlnet_qr]

pipe = StableDiffusionControlNetPipeline(**components).to("cuda")

lora_model_file = './weights-cache/Lora/blindbox_v1_mix.safetensors'
pipe.load_lora_weights(lora_model_file, cache_dir=CACHE_DIR)

pipe = pipe.to("cuda", torch.float16)

device = 'cuda'
generator = torch.Generator(device=device)
generator = generator.manual_seed(seed)

prompt = '(masterpiece),(best quality),(ultra-detailed), (full body:1.2),1girl,chibi,cute, smile, open mouth,flower, outdoors, playing guitar, music, beret, holding guitar, jacket, blush, tree, :3, shirt, short hair, cherry blossoms, green headwear, blurry, brown hair, blush stickers, long sleeves, bangs, headphones, black hair, pink flower,(beautiful detailed face), (beautiful detailed eyes)'
negative_prompt = '(low quality:1.3), (worst quality:1.3)'
guidance_scale = 7
num_inference_steps = 35

scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)
pipe.scheduler = scheduler
pipe.scheduler.set_timesteps(num_inference_steps)

images = pipe(
prompt=prompt, 
negative_prompt=negative_prompt,
guidance_scale=guidance_scale,
num_inference_steps=num_inference_steps,
generator=generator,
image=[qrImage, qrImage],
controlnet_conditioning_scale=[1.0, 1.0],
control_guidance_start=[0.3, 0],
control_guidance_end=[0.7, 1]
).images[0]

images.save(f'output.png')