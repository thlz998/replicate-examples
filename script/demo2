#!/usr/bin/env python3
import sys
from huggingface_hub import login
import torch
import time as time_
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, StableDiffusionPipeline, EulerDiscreteScheduler
from lora_diffusion import LoRAManager
from PIL import Image

CACHE_DIR = "weights-cache"
sys.path.append(".")

seed = 1383557390

model_key_base_safetensors = "./weights-cache/models/revAnimated_v122.safetensors"

pipe = StableDiffusionPipeline.from_single_file(
        model_key_base_safetensors,
        torch_dtype=torch.float16,
        cache_dir=CACHE_DIR).to("cuda")

components = pipe.components

pipe = StableDiffusionControlNetPipeline(components)

lora_model_file = './weights-cache/Lora/blindbox_v1_mix.safetensors'
pipe.load_lora_weights(lora_model_file, cache_dir=CACHE_DIR)

pipe = pipe.to("cuda", torch.float16)

device = 'cuda'
generator = torch.Generator(device=device)
generator = generator.manual_seed(seed)

prompt = '(masterpiece),(best quality),(ultra-detailed), (full body:1.2),1girl,chibi,cute, smile, open mouth,flower, outdoors, playing guitar, music, beret, holding guitar, jacket, blush, tree, :3, shirt, short hair, cherry blossoms, green headwear, blurry, brown hair, blush stickers, long sleeves, bangs, headphones, black hair, pink flower,(beautiful detailed face), (beautiful detailed eyes)'
negative_prompt = '(low quality:1.3), (worst quality:1.3)'
guidance_scale = 7
num_inference_steps = 28

scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)
pipe.scheduler = scheduler
pipe.scheduler.set_timesteps(num_inference_steps)

images = pipe(
prompt=[prompt], 
negative_prompt=[negative_prompt],
guidance_scale=guidance_scale,
num_inference_steps=num_inference_steps,
generator=generator).images

images[0].save(f'output.png')