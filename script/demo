#!/usr/bin/env python3
import sys
from huggingface_hub import login
import torch
from controlnet_aux import OpenposeDetector
# from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, DPMSolverMultistepScheduler
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel
import cv2
import numpy as np
from PIL import Image

CACHE_DIR = "weights-cache"
login(token="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")
sys.path.append(".")


cannyImage = Image.open('input.jpeg')
cannyImage = np.array(cannyImage)

low_threshold = 100
high_threshold = 200

cannyImage = cv2.Canny(cannyImage, low_threshold, high_threshold)
cannyImage = cannyImage[:, :, None]
cannyImage = np.concatenate([cannyImage, cannyImage, cannyImage], axis=2)
canny_image = Image.fromarray(cannyImage)
canny_image.save('canny.png')

# openImage
openImage = Image.open('input.jpeg')
openpose = OpenposeDetector.from_pretrained(
        'lllyasviel/ControlNet',
        cache_dir=CACHE_DIR)
pose_image = openpose(openImage)
pose_image.save('pose.png')

# 加载模型
controlnet_canny = ControlNetModel.from_pretrained(
        "lllyasviel/sd-controlnet-canny", 
        cache_dir=CACHE_DIR,
        torch_dtype=torch.float16)
controlnet_pose = ControlNetModel.from_pretrained(
        "lllyasviel/sd-controlnet-openpose", 
        torch_dtype=torch.float16,
        cache_dir=CACHE_DIR)

pipe = StableDiffusionControlNetPipeline.from_pretrained(
 "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16,
 controlnet=[
  controlnet_pose, 
  controlnet_canny
 ],
 cache_dir=CACHE_DIR,
).to("cuda")
generator = torch.Generator(device='cuda').manual_seed(12345)
image = pipe(
        image=[pose_image, canny_image],
        width=512,
        height=768,
        prompt= "a beautiful hollywood actress wearing black dress attending award winning event, red carpet stairs at background",
        negative_prompt="cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, blurry, bad anatomy, bad proportions",
        num_inference_steps=20,
        generator=generator,
        controlnet_conditioning_scale=[1.0,1.0]
        ).images[0]
image.save("output.png")