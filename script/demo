#!/usr/bin/env python3
import sys
from huggingface_hub import login
import torch
# from controlnet_aux import OpenposeDetector
# from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, DPMSolverMultistepScheduler
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, StableDiffusionPipeline
# import cv2
# import numpy as np
from PIL import Image

CACHE_DIR = "weights-cache"
login(token="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")
sys.path.append(".")

qrImage = Image.open('k0a1a.png')

controlnet_qr_monster = ControlNetModel.from_pretrained(
        "monster-labs/control_v1p_sd15_qrcode_monster", 
        torch_dtype=torch.float16,
        cache_dir=CACHE_DIR).to("cuda")

pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
#     CACHE_DIR,
#     model_name = "revAnimated_v122",
    torch_dtype=torch.float16,
    controlnet=[controlnet_qr_monster],
    cache_dir=CACHE_DIR,
).to("cuda")


# pipeline.load_lora_weights（ “。”，weight_name = “light_and_shadow.safetensors”）
# cpu卸载以节省内存，需要加速>=0.17.0
pipe.enable_model_cpu_offload() 

generator = torch.Generator(device='cuda').manual_seed(941189224)
pipe.unet.load_attn_procs("sayakpaul/sd-model-finetuned-lora-t4", cache_dir=CACHE_DIR)
image = pipe(
        image=[qrImage],
        width=512,
        height=512,
        prompt= "(masterpiece),(best quality),(ultra-detailed), (full body:1.2),1girl,chibi,cute, smile, open mouth,flower, outdoors, playing guitar, music, beret, holding guitar, jacket, blush, tree, :3, shirt, short hair, cherry blossoms, green headwear, blurry, brown hair, blush stickers, long sleeves, bangs, headphones, black hair, pink flower,(beautiful detailed face), (beautiful detailed eyes)",
        negative_prompt="(low quality:1.3), (worst quality:1.3)",
        generator=generator,
        num_inference_steps=30,
        control_guidance_start=[0.2],
        control_guidance_end=[0.8],
        controlnet_conditioning_scale=[1.0,1.0],
        # control_image=[control_image, control_image],
        # guidance_scale=float(guidance_scale),
        # strength=float(strength),
        ).images[0]
image.save("output1.png")
