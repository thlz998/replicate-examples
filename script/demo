#!/usr/bin/env python3
import sys
from huggingface_hub import login
import torch
import os
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, StableDiffusionPipeline
from lora_diffusion import LoRAManager
from PIL import Image

CACHE_DIR = "weights-cache"
# login(token="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")
sys.path.append(".")

qrImage = Image.open('k0a1a.png')


controlnet_qr = ControlNetModel.from_pretrained(
        "Nacholmo/controlnet-qr-pattern", 
        torch_dtype=torch.float16,
        cache_dir=CACHE_DIR).to("cuda")

# 下载大模型
# pipe = StableDiffusionPipeline.from_single_file(
#     "https://huggingface.co/hanafuusen2001/ReVAnimated/revAnimated_v122.safetensors",
#     cache_dir=CACHE_DIR,
# ).to("cuda")
# pipe = None

# 加载模型
pipe = StableDiffusionControlNetPipeline.from_pretrained(
        # "runwayml/stable-diffusion-v1-5",
        # "SG161222/Realistic_Vision_V4.0",
        "LottePeisch/RevAnimated-Diffusers",
        torch_dtype=torch.float16,
        controlnet=[
        controlnet_qr,
        ],
        cache_dir=CACHE_DIR,
).to("cuda")


# 加载lora
lora_scales = [1.0, 0.6]  # 与lora_paths一一对应的scale值
print("11111----------------------------")
lora_paths=["weights-cache/Lora/tmpan_f4msxcaravaggio.safetensors", "weights-cache/Lora/tmpan_f4msxcaravaggio.safetensors"]
print("22222----------------------------")

lora_manager = LoRAManager(lora_paths, pipe)
lora_manager.tune(lora_scales)
prompt = "<1>,<2>,(masterpiece),(best quality),(ultra-detailed), (full body:1.2),1girl,chibi,cute, smile, open mouth,flower, outdoors, playing guitar, music, beret, holding guitar, jacket, blush, tree, :3, shirt, short hair, cherry blossoms, green headwear, blurry, brown hair, blush stickers, long sleeves, bangs, headphones, black hair, pink flower,(beautiful detailed face), (beautiful detailed eyes)"
prompt = lora_manager.prompt(prompt)
print("----------------------------------")
print(prompt)
print("----------------------------------")

generator = torch.Generator(device='cuda').manual_seed(12345)
# cpu卸载以节省内存，需要加速>=0.17.0
pipe.enable_model_cpu_offload() 
image = pipe(
        image=[qrImage],
        width=512,
        height=512,
        prompt= prompt,
        negative_prompt="(low quality:1.3), (worst quality:1.3)",
        num_inference_steps=50,
        generator=generator,
        controlnet_conditioning_scale=[1.0,1.0],
        # control_image=[control_image, control_image],
        # guidance_scale=float(guidance_scale),
        # strength=float(strength),
        ).images[0]
image.save("output.png")