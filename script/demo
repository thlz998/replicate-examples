#!/usr/bin/env python3
import sys
from huggingface_hub import login
import torch
from controlnet_aux import OpenposeDetector
# from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, DPMSolverMultistepScheduler
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel
from PIL import Image

CACHE_DIR = "weights-cache"
login(token="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")
sys.path.append(".")

qrImage = Image.open('qr-code-6.png')


controlnet_qr = ControlNetModel.from_pretrained(
        "Nacholmo/controlnet-qr-pattern", 
        torch_dtype=torch.float16,
        cache_dir=CACHE_DIR).to("cuda")

pipe = StableDiffusionControlNetPipeline.from_pretrained(
 "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16,
 controlnet=[
  controlnet_qr,
 ],
 cache_dir=CACHE_DIR,
).to("cuda")
# cpu卸载以节省内存，需要加速>=0.17.0
pipe.enable_model_cpu_offload() 

generator = torch.Generator(device='cuda').manual_seed(12345)
pipe.unet.load_attn_procs("sayakpaul/sd-model-finetuned-lora-t4", cache_dir=CACHE_DIR)
image = pipe(
        image=[qrImage],
        # image=[qrImage, qrImage],
        width=512,
        height=768,
        prompt= "a beautiful hollywood actress wearing black dress attending award winning event, red carpet stairs at background",
        negative_prompt="cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, blurry, bad anatomy, bad proportions",
        num_inference_steps=50,
        generator=generator,
        controlnet_conditioning_scale=[1.0,1.0],
        # control_image=[control_image, control_image],
        # guidance_scale=float(guidance_scale),
        # strength=float(strength),
        ).images[0]
image.save("output.png")