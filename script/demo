#!/usr/bin/env python3
import sys
from huggingface_hub import login
import torch
from controlnet_aux import OpenposeDetector
# from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, DPMSolverMultistepScheduler
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel
import cv2
import numpy as np
from PIL import Image

CACHE_DIR = "weights-cache"
login(token="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")
sys.path.append(".")

qrImage = Image.open('k0a1a.png')


cannyImage = Image.open('k0a1a.png')
cannyImage = np.array(cannyImage)

low_threshold = 100
high_threshold = 200

cannyImage = cv2.Canny(cannyImage, low_threshold, high_threshold)
cannyImage = cannyImage[:, :, None]
cannyImage = np.concatenate([cannyImage, cannyImage, cannyImage], axis=2)
canny_image = Image.fromarray(cannyImage)
canny_image.save('canny.png')

# openImage
openImage = Image.open('k0a1a.png')
openpose = OpenposeDetector.from_pretrained(
        'lllyasviel/ControlNet',
        cache_dir=CACHE_DIR)
pose_image = openpose(openImage)
pose_image.save('pose.png')

# 加载模型
# controlnet_canny = ControlNetModel.from_pretrained(
#         "lllyasviel/sd-controlnet-canny", 
#         cache_dir=CACHE_DIR,
#         torch_dtype=torch.float16)
# controlnet_pose = ControlNetModel.from_pretrained(
#         "lllyasviel/sd-controlnet-openpose", 
#         torch_dtype=torch.float16,
#         cache_dir=CACHE_DIR)
controlnet_qr = ControlNetModel.from_pretrained(
        "Nacholmo/controlnet-qr-pattern", 
        torch_dtype=torch.float16,
        cache_dir=CACHE_DIR).to("cuda")

pipe = StableDiffusionControlNetPipeline.from_pretrained(
 "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16,
 controlnet=[
#   controlnet_pose, 
#   controlnet_canny,
#   controlnet_qr,
  controlnet_qr,
 ],
 cache_dir=CACHE_DIR,
).to("cuda")
# cpu卸载以节省内存，需要加速>=0.17.0
pipe.enable_model_cpu_offload() 

generator = torch.Generator(device='cuda').manual_seed(12345)
pipe.unet.load_attn_procs("sayakpaul/sd-model-finetuned-lora-t4", cache_dir=CACHE_DIR)
image = pipe(
        image=[qrImage],
        # image=[qrImage, qrImage],
        width=512,
        height=768,
        prompt= "a beautiful hollywood actress wearing black dress attending award winning event, red carpet stairs at background",
        negative_prompt="cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, blurry, bad anatomy, bad proportions",
        num_inference_steps=50,
        generator=generator,
        controlnet_conditioning_scale=[1.0,1.0],
        # control_image=[control_image, control_image],
        # guidance_scale=float(guidance_scale),
        # strength=float(strength),
        ).images[0]
image.save("output.png")


# Steps: 20,
# Sampler: DPM++ 2M SDE Karras,
# CFG scale: 7,
# Seed: 4157771897,
# Size: 512x512,
# Model: [吉卜力水彩风]ghibliStyleMix_v10,
# ControlNet 0: "preprocessor: none,
# model: controlnetQRPatternQR_v20 [2d8d5750],
# weight: 1,
# starting/ending: (0,
# 0.85),
# resize mode: Crop and Resize,
# pixel perfect: True,
# control mode: Balanced,
# preprocessor params: (512,
# 64,
# 64)",
# ControlNet 1: "preprocessor: none,
# model: control_v1p_sd15_qrcode_monster [a6e58995],
# weight: 0.3,
# starting/ending: (0,
# 1),
# resize mode: Crop and Resize,
# pixel perfect: True,
# control mode: Balanced,
# preprocessor params: (512,
# 64,
# 64)",
# Version: v1.4.1